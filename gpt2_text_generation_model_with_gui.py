# -*- coding: utf-8 -*-
"""GPT2 Text Generation Model with GUI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yvZq0WDxXfgWR0TnaH8pKwCamX-Wwqnl
"""

!pip install -q gradio
!pip install transformers

import gradio as gr

import tensorflow as tf
from transformers import GPT2Tokenizer, GPT2LMHeadModel

tokenizer= GPT2Tokenizer.from_pretrained("gpt2")
model= GPT2LMHeadModel.from_pretrained("gpt2",pad_token_id=tokenizer.eos_token_id)

def generate_text(prompt):
    inputs = tokenizer.encode(prompt, return_tensors="pt")
    outputs = model.generate(
    inputs,
    max_length=100,
    num_return_sequences=1,
    temperature=0.7,         # controls creativity
    top_k=50,                # limits sampling to top 50 words
    top_p=0.95,              # nucleus sampling
    repetition_penalty=1.2,  # discourages repeating words/phrases
    no_repeat_ngram_size=2   # prevents repeating 2-word sequences
)

    return tokenizer.decode(outputs[0], skip_special_tokens=True)

iface = gr.Interface(
    fn=generate_text,                 # your function
    inputs=gr.Textbox(lines=2, placeholder="Enter your prompt here..."),
    outputs=gr.Textbox(),
    title="GPT-2 Text Generator",
    description="OpenAI's GPT-2 can generate coherent text. Enter a sentence and see what it completes with!"
)

iface.launch()